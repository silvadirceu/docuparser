{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5edf5643",
            "metadata": {},
            "source": [
                "Para rodar o notebook testes_ocr.ipynb\n",
                " completamente, você precisará preparar o ambiente e criar contas em alguns serviços, pois ele utiliza tanto ferramentas locais quanto APIs na nuvem.\n",
                "\n",
                "Aqui está o checklist do que você precisa fazer:\n",
                "\n",
                "1. Instalações no Sistema (Mac)\n",
                "O notebook usa o Tesseract (para OCR básico) e o Poppler (para manipular PDFs). Eles não são instalados via Python, precisam ser instalados no sistema. Abra seu terminal e rode:\n",
                "\n",
                "```\n",
                "bash\n",
                "brew install tesseract poppler\n",
                "```\n",
                "\n",
                "2. Dependências Python\n",
                "No próprio notebook, a primeira célula de código instala as bibliotecas necessárias. Certifique-se de rodá-la:\n",
                "\n",
                "```\n",
                "python\n",
                "!pip install opencv-python pytesseract pdf2image easyocr pdfplumber matplotlib numpy\n",
                "!pip install landingai docling llama-parse unstructured\n",
                "```\n",
                "\n",
                "3. Contas e Chaves de API (Necessário Cadastro)\n",
                "\n",
                "Algumas bibliotecas do notebook são serviços pagos ou que exigem autenticação na nuvem. Você precisará criar conta para obter as chaves:\n",
                "\n",
                "LlamaParse (LlamaIndex)\n",
                "- Para que serve: Extração inteligente de PDFs para RAG.\n",
                "- Onde criar conta: Vá ao site da LlamaCloud e faça login (geralmente via GitHub/Google).\n",
                "- O que fazer: Gere uma LLAMA_CLOUD_API_KEY e coloque-a na célula correspondente do notebook.\n",
                "\n",
                "LandingAI (Vision Agent)\n",
                "- Para que serve: Agente de visão computacional que aceita comandos em texto natural.\n",
                "- Onde criar conta: Vá ao site da LandingAI (ou LandingLens).\n",
                "O que fazer: Obtenha a LANDINGAI_API_KEY. (Nota: verifique se há free tier disponível, pois é um serviço comercial).\n",
                "\n",
                "4. Arquivos de Teste\n",
                "\n",
                "O notebook faz referência a arquivos locais que não parecem existir na pasta ainda:\n",
                "\n",
                "- exemplo_nota_fiscal.pdf\n",
                "- exemplo_manuscrito.jpg\n",
                "- exemplo_tabela.pdf\n",
                "\n",
                "Você precisará colocar arquivos reais com esses nomes na mesma pasta do notebook ou alterar o código para apontar para seus próprios arquivos de teste.\n",
                "\n",
                "Resumo\n",
                "\n",
                "Se você quiser rodar apenas o básico (Tesseract, EasyOCR, Docling, Unstructured local), só precisa das instalações no passo 1 e 2. Se quiser testar as ferramentas avançadas de IA (LlamaParse, LandingAI), precisará dos cadastros no passo 3."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Testes de Técnicas de OCR para Documentos Diversos\n",
                "\n",
                "Este notebook tem como objetivo testar e comparar diferentes bibliotecas e técnicas de OCR (Optical Character Recognition) para leitura de:\n",
                "1. Notas fiscais (Documentos estruturados/semi-estruturados)\n",
                "2. Tabelas em PDFs\n",
                "3. Imagens com texto escrito à mão\n",
                "\n",
                "## Bibliotecas Utilizadas:\n",
                "- **Tesseract (pytesseract)**: Padrão da indústria, bom para textos digitalizados limpos.\n",
                "- **EasyOCR**: Baseado em Deep Learning, costuma ser mais robusto para texto em cenários naturais e escrita manual.\n",
                "- **pdfplumber**: Excelente para extração direta de dados e tabelas de PDFs nativos (não escaneados).\n",
                "- **OpenCV**: Para pré-processamento de imagens (binarização, redução de ruído).\n",
                "- **LandingAI DPT-2**: Document Pre-trained Transformer para extração inteligente.\n",
                "- **IBM Docling**: Solução completa de parsing de documentos.\n",
                "- **LlamaParse**: Parser poderoso da LlamaIndex focado em RAG.\n",
                "- **Unstructured.io**: Toolkit flexível para ingestão de dados não estruturados."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Instalação e Configuração\n",
                "**Nota:** Para o `pytesseract` funcionar, você precisa ter o binário do Tesseract instalado no seu sistema:\n",
                "- **Mac**: `brew install tesseract poppler`\n",
                "- **Linux**: `sudo apt install tesseract-ocr poppler-utils`\n",
                "- **Windows**: Baixar o instalador oficial."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instalação das dependências Python\n",
                "!pip install opencv-python pytesseract pdf2image easyocr pdfplumber matplotlib numpy\n",
                "!pip install landingai docling llama-parse unstructured"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import pytesseract\n",
                "import easyocr\n",
                "import pdfplumber\n",
                "from pdf2image import convert_from_path\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import os\n",
                "\n",
                "# Configuração para exibir imagens no notebook\n",
                "def mostrar_imagem(img, titulo=\"Imagem\"):\n",
                "    plt.figure(figsize=(10, 10))\n",
                "    if len(img.shape) == 3:\n",
                "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
                "    else:\n",
                "        plt.imshow(img, cmap='gray')\n",
                "    plt.title(titulo)\n",
                "    plt.axis('off')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preparação dos Dados\n",
                "Coloque seus arquivos de teste na pasta local ou defina os caminhos abaixo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Defina os caminhos dos seus arquivos de teste aqui\n",
                "arquivo_pdf_nota = \"exemplo_nota_fiscal.pdf\"  # Substitua pelo seu arquivo\n",
                "arquivo_imagem_mao = \"exemplo_manuscrito.jpg\" # Substitua pelo seu arquivo\n",
                "arquivo_pdf_tabela = \"exemplo_tabela.pdf\"     # Substitua pelo seu arquivo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. OCR com Tesseract (Generalista)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def ocr_tesseract(caminho_imagem):\n",
                "    img = cv2.imread(caminho_imagem)\n",
                "    \n",
                "    # Pré-processamento simples: converter para escala de cinza\n",
                "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
                "    \n",
                "    # Binarização (Threshold) pode ajudar em documentos ruidosos\n",
                "    # _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
                "    \n",
                "    mostrar_imagem(img, \"Imagem Original\")\n",
                "    \n",
                "    # OCR\n",
                "    # config='--psm 6' assume um bloco único de texto uniforme\n",
                "    texto = pytesseract.image_to_string(gray, lang='por') \n",
                "    return texto\n",
                "\n",
                "# Exemplo de uso (descomente se tiver o arquivo):\n",
                "# print(\"--- Resultado Tesseract ---\")\n",
                "# print(ocr_tesseract(arquivo_imagem_mao))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. OCR com EasyOCR (Manuscrito e Deep Learning)\n",
                "O EasyOCR costuma ser melhor para textos artísticos, manuscritos ou em fotos naturais."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "reader = easyocr.Reader(['pt', 'en'], gpu=False) # Defina gpu=True se tiver CUDA\n",
                "\n",
                "def ocr_easyocr(caminho_imagem):\n",
                "    img = cv2.imread(caminho_imagem)\n",
                "    mostrar_imagem(img, \"Entrada EasyOCR\")\n",
                "    \n",
                "    result = reader.readtext(caminho_imagem)\n",
                "    \n",
                "    texto_completo = \"\"\n",
                "    for (bbox, text, prob) in result:\n",
                "        if prob > 0.5: # Filtrar leituras com baixa confiança\n",
                "            print(f\"Detectado: {text} (Confiança: {prob:.2f})\")\n",
                "            texto_completo += text + \" \"\n",
                "            \n",
                "            # Desenhando bbox na imagem para visualização\n",
                "            (tl, tr, br, bl) = bbox\n",
                "            tl = (int(tl[0]), int(tl[1]))\n",
                "            br = (int(br[0]), int(br[1]))\n",
                "            cv2.rectangle(img, tl, br, (0, 255, 0), 2)\n",
                "            \n",
                "    mostrar_imagem(img, \"Detectado EasyOCR\")\n",
                "    return texto_completo\n",
                "\n",
                "# Exemplo de uso:\n",
                "# print(ocr_easyocr(arquivo_imagem_mao))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Extração de Tabelas de PDFs (PdfPlumber)\n",
                "Para notas fiscais e relatórios que são PDFs digitais (text-based), não use OCR de imagem. Use extração direta."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extrair_tabelas_pdf(caminho_pdf):\n",
                "    with pdfplumber.open(caminho_pdf) as pdf:\n",
                "        for i, page in enumerate(pdf.pages):\n",
                "            print(f\"--- Página {i+1} ---\")\n",
                "            \n",
                "            # Extrair texto puro\n",
                "            texto = page.extract_text()\n",
                "            print(\"Conteúdo textual:\")\n",
                "            print(texto[:200] + \"...\") # Preview\n",
                "            \n",
                "            # Extrair tabelas\n",
                "            tabelas = page.extract_tables()\n",
                "            for j, tabela in enumerate(tabelas):\n",
                "                print(f\"\\nTabela {j+1}:\")\n",
                "                for linha in tabela:\n",
                "                    print(linha)\n",
                "                    \n",
                "# Exemplo de uso:\n",
                "# extrair_tabelas_pdf(arquivo_pdf_tabela)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Processamento de Imagens de Notas Fiscais (OCR + Regex)\n",
                "Muitas vezes precisamos localizar campos específicos (CNPJ, Data, Valor) após o OCR."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "\n",
                "def buscar_info_nota(texto):\n",
                "    # Exemplos de Regex comuns em notas brasileiras\n",
                "    regex_cnpj = r\"\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}\"\n",
                "    regex_data = r\"\\d{2}/\\d{2}/\\d{4}\"\n",
                "    regex_valor = r\"R\\$ ?[\\d\\.,]+\"\n",
                "    \n",
                "    cnpjs = re.findall(regex_cnpj, texto)\n",
                "    datas = re.findall(regex_data, texto)\n",
                "    valores = re.findall(regex_valor, texto)\n",
                "    \n",
                "    return {\n",
                "        \"cnpjs\": cnpjs,\n",
                "        \"datas\": datas,\n",
                "        \"valores\": valores\n",
                "    }\n",
                "\n",
                "# Teste integrado\n",
                "# texto_extraido = ocr_tesseract(arquivo_pdf_nota_convertido_para_img)\n",
                "# info = buscar_info_nota(texto_extraido)\n",
                "# print(info)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. LandingAI DPT-2 (Vision Agent)\n",
                "O DPT-2 é focado em transformar documentos visuais em dados estruturados usando transformers pré-treinados.\n",
                "**Nota**: Necessita API Key."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install landingai\n",
                "import os\n",
                "\n",
                "# Defina sua chave de API aqui\n",
                "# os.environ[\"LANDINGAI_API_KEY\"] = \"sua-chave-aqui\"\n",
                "\n",
                "try:\n",
                "    from landingai.pipeline.image_source import ImageSource\n",
                "    # Exemplo genérico de uso da lib (ajuste conforme a documentação mais recente do Vision Agent)\n",
                "    # O Vision Agent permite comandos em linguagem natural para processar a imagem\n",
                "    \n",
                "    def processar_landingai(caminho_imagem):\n",
                "        if \"LANDINGAI_API_KEY\" not in os.environ:\n",
                "            print(\"Erro: LANDINGAI_API_KEY não definida.\")\n",
                "            return\n",
                "            \n",
                "        print(\"Iniciando LandingAI...\")\n",
                "        # Exemplo hipotético de uso do agente\n",
                "        # from landingai.agent import VisionAgent\n",
                "        # agent = VisionAgent()\n",
                "        # resposta = agent.run(\"Extraia o valor total e a data desta nota fiscal.\", image_path=caminho_imagem)\n",
                "        # print(resposta)\n",
                "        \n",
                "except ImportError:\n",
                "    print(\"Biblioteca landingai não instalada ou erro na importação.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. IBM Docling\n",
                "Docling é uma biblioteca poderosa da IBM para conversão de documentos complexos (PDFs com tabelas, fórmulas, etc) em formatos estruturados como Markdown ou JSON."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install docling\n",
                "\n",
                "try:\n",
                "    from docling.document_converter import DocumentConverter\n",
                "\n",
                "    def processar_docling(caminho_fonte):\n",
                "        print(f\"Processando {caminho_fonte} com Docling...\")\n",
                "        converter = DocumentConverter()\n",
                "        result = converter.convert(caminho_fonte)\n",
                "        \n",
                "        # Exportar para Markdown\n",
                "        md_output = result.document.export_to_markdown()\n",
                "        print(\"--- Resultado Markdown (Docling) ---\")\n",
                "        print(md_output[:500] + \"...\") # Preview\n",
                "        return md_output\n",
                "\n",
                "    # Exemplo de uso:\n",
                "    # processar_docling(arquivo_pdf_nota)\n",
                "\n",
                "except ImportError:\n",
                "    print(\"Biblioteca docling não instalada.\")\n",
                "except Exception as e:\n",
                "    print(f\"Erro ao executar Docling: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. LlamaParse (LlamaIndex)\n",
                "Projetado especificamente para aplicações RAG (Retrieval-Augmented Generation), o LlamaParse é excelente em transformar documentos complexos em texto limpo.\n",
                "**Nota**: Requer API Key da LlamaCloud."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install llama-parse\n",
                "import os\n",
                "\n",
                "# os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-...\"\n",
                "\n",
                "try:\n",
                "    import nest_asyncio\n",
                "    nest_asyncio.apply() # Necessário para rodar loops de evento em notebooks\n",
                "    from llama_parse import LlamaParse\n",
                "\n",
                "    def processar_llamaparse(caminho_pdf):\n",
                "        if \"LLAMA_CLOUD_API_KEY\" not in os.environ:\n",
                "            print(\"Erro: LLAMA_CLOUD_API_KEY não definida.\")\n",
                "            return\n",
                "\n",
                "        print(f\"Processando {caminho_pdf} com LlamaParse...\")\n",
                "        parser = LlamaParse(\n",
                "            result_type=\"markdown\",  # \"markdown\" ou \"text\"\n",
                "            verbose=True,\n",
                "            language=\"pt\" # Opcional\n",
                "        )\n",
                "        \n",
                "        # O LlamaParse pode carregar o arquivo e parsear\n",
                "        documents = parser.load_data(caminho_pdf)\n",
                "        \n",
                "        for doc in documents:\n",
                "            print(\"--- Página/Trecho ---\")\n",
                "            print(doc.text[:500] + \"...\")\n",
                "            \n",
                "    # Exemplo de uso\n",
                "    # processar_llamaparse(arquivo_pdf_nota)\n",
                "\n",
                "except ImportError:\n",
                "    print(\"Biblioteca llama-parse não instalada.\")\n",
                "except Exception as e:\n",
                "    print(f\"Erro no LlamaParse: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Unstructured.io\n",
                "Ferramenta versátil para ingestão (\"partitioning\") de diversos formatos (PDF, DOCX, HTML, Imagens). Pode rodar local (dependências de sistema) ou via API."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install unstructured\n",
                "# Para suporte a PDF local, é necessário instalar dependências do sistema como poppler e tesseract\n",
                "\n",
                "try:\n",
                "    from unstructured.partition.pdf import partition_pdf\n",
                "    from unstructured.partition.image import partition_image\n",
                "\n",
                "    def processar_unstructured_pdf(caminho_pdf):\n",
                "        print(f\"Processando {caminho_pdf} com Unstructured...\")\n",
                "        \n",
                "        # partition_pdf tenta extrair texto, tabelas, etc.\n",
                "        # strategy=\"hi_res\" usa OCR e análise visual (mais lento, mais preciso)\n",
                "        # strategy=\"fast\" extrai texto diretamente (somente PDFs nativos)\n",
                "        elements = partition_pdf(\n",
                "            filename=caminho_pdf,\n",
                "            strategy=\"hi_res\", # Mude para \"fast\" para teste rápido\n",
                "            infer_table_structure=True\n",
                "        )\n",
                "        \n",
                "        print(f\"Total de elementos extraídos: {len(elements)}\")\n",
                "        for el in elements[:5]:\n",
                "            print(f\"[{el.category}]: {el.text}\")\n",
                "            \n",
                "    # Exemplo de uso\n",
                "    # processar_unstructured_pdf(arquivo_pdf_nota)\n",
                "\n",
                "except ImportError:\n",
                "    print(\"Biblioteca unstructured não instalada.\")\n",
                "except Exception as e:\n",
                "    print(f\"Erro no Unstructured: {e}. Verifique se poppler/tesseract estão instalados.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
